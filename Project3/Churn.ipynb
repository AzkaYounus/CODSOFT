{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/tpd7h5x56xb7pt4x4vbbly0m0000gn/T/ipykernel_10228/3418272137.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/azkayounus/Desktop/CODSOFT/Project3/Churn_Modelling.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop irrelevant columns (e.g., RowNumber, CustomerId, Surname)\n",
    "data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "# Drop duplicate rows\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop rows with null values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Split features and target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split features and target variable\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "categorical_features = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preprocessing pipeline for numerical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Logistic Regression model\n",
    "lr_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Gradient Boosting model\n",
    "gb_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('classifier', GradientBoostingClassifier())])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train and evaluate models\n",
    "models = {'Logistic Regression': lr_model,\n",
    "          'Random Forest': rf_model,\n",
    "          'Gradient Boosting': gb_model}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression Model Accuracy: 0.811\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[1543   64]\n",
      " [ 314   79]]\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1607\n",
      "           1       0.55      0.20      0.29       393\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.69      0.58      0.59      2000\n",
      "weighted avg       0.78      0.81      0.77      2000\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Model Accuracy: 0.8685\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[1548   59]\n",
      " [ 204  189]]\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1607\n",
      "           1       0.76      0.48      0.59       393\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.82      0.72      0.76      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Model Accuracy: 0.8645\n",
      "\n",
      "Confusion Matrix for Gradient Boosting:\n",
      "[[1542   65]\n",
      " [ 206  187]]\n",
      "\n",
      "Classification Report for Gradient Boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1607\n",
      "           1       0.74      0.48      0.58       393\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.81      0.72      0.75      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'Training {name}...')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f'{name} Model Accuracy: {accuracy_score(y_test, y_pred)}\\n')\n",
    "    print(f'Confusion Matrix for {name}:\\n{confusion_matrix(y_test, y_pred)}\\n')\n",
    "    print(f'Classification Report for {name}:\\n{classification_report(y_test, y_pred)}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
